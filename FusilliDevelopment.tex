\chapter{Fusilli: Developing a Data Fusion Python Library}
\label{fusilli_development}

\textbf{Linking sentence from Cox chapter:
We've seen how multimodal data affects a survival Cox model in MND.
What about machine learning for multimodal data?}

This chapter discusses multimodal data fusion in more detail and describe the development of Fusilli, a Python package for multimodal data fusion experimentation and analysis.

\section{Introduction}

Multimodal data fusion is the process of combining data from different sources to make predictions or decisions, often through the use of deep learning.
The goal of combining different modalities is to improve the performance of a model by leveraging the relevant information from each modality and fusing them in a way that improves the model's performance.
There are many research fields where multimodal data fusion is used, such as in agriculture to predict crop yields and detect diseases~\cite{s.s.gopiMultimodalMachineLearning2023, patilRiceFusionMultimodalityData2022}, in disaster management to analyse response scenarios from audio and social media posts~\cite{algiriyageMultisourceMultimodalData2021}, and in robotics to help direct the robots with multiple sensors~\cite{duanMultimodalSensorsMLBased2022}.
Moreover, the types of models used in multimodal data fusion can vary a lot, from geometric deep learning to relatively simple neural network architectures~\cite{cuiDeepMultimodalFusion2022}.

%In the context of my PhD, I am investigating multimodal data fusion for MND prognosis prediction.
%There has been minimal research on deep learning for prognosis prediction in MND~\cite{pancottiDeepLearningMethods2022, mullerExplainableModelsDisease2021}, and only one model created for deep-learning based multimodal data fusion~\cite{vanderburghDeepLearningPredictions2017}.
%However, there are many data fusion models that have been used in other fields that could be directly applicable to MND .
%There have been systematic reviews on the topic of data fusion that compare models, but only qualitatively~\cite{cuiDeepMultimodalFusion2022, gaoSurveyDeepLearning2020, stahlschmidtMultimodalDeepLearning2022, yanDeepMultiviewLearning2021}.
%Therefore, with limited knowledge from literature on the best models for MND data, it is important to experiment with a wide variety of models to find the best one for the task.

My PhD investigates multimodal data fusion for predicting MND prognosis, an area with minimal deep learning research~\cite{pancottiDeepLearningMethods2022, mullerExplainableModelsDisease2021} and only one model specially-created for deep-learning based multimodal data fusion~\cite{vanderburghDeepLearningPredictions2017}.
Despite systematic reviews on the topic attempting qualitative comparison between models~\cite{cuiDeepMultimodalFusion2022, gaoSurveyDeepLearning2020, stahlschmidtMultimodalDeepLearning2022, yanDeepMultiviewLearning2021}, a lack of quantitative comparison necessitates experimentation with many models from other fields to identify the most effective for MND prognosis prediction.

%Obtaining this wide variety of models to experiment with, however, is not a straightforward process for a number of reasons.
%Firstly, the terminology used to describe what I have chosen to call ``multimodal data fusion`` varies widely, with terms such as but not limited to multi-view, cross-heterogeneous, multi-source, and integrated learning.
%Secondly, the studies that introduce these models often do not include code for the reader to run the model.
%Morever, when code is included, it is often written in different languages, with varying guidance, quality, and maintenance.
However, acquring a diverse range of models for experimentation is made difficult by the use of variable terminology and the common absence of maintained, quality code available in studies.

A way to address these problems is to create a curated collection of models for somebody interested in multimodal data fusion to consult.
As far as I am aware, there are three Python packages that house collections of deep learning based data fusion models: ``Multi-view-AE``~\cite{aguilaMultiviewAEPythonPackage2023}, ``CCA-Zoo``~\cite{chapmanCCAZooCollectionRegularized2021}, and ``pytorch-widedeep``~\cite{zaurinPytorchwidedeepFlexiblePackage2023}.
However, each of these packages only includes models with specific frameworks (autoencoders, CCA, and Google's ``wide and deep`` models, respectively), which limits the variety of models available for comparison.

Therefore, I aimed to develop a Python package for training and comparing multimodal data fusion models with any architecture.
This Python package is named Fusilli, as a portmanteau of ``fuse easily``.

\section{Development}

\subsection{Software Design Choices}

Before designing Fusilli, I had the following design goals to ensure the package would be useful for a wide range of users and tasks, as well as for my own research.\newline

\noindent\textbf{Modularity}: Fusilli should be modular, meaning that the various functionalities within the package should be independent of each other.
This would allow for easy addition of new models in the future and easy adjustments to the package's functionality.\newline

\noindent\textbf{Beginner-friendly and expert-friendly}:  Fusilli should be beginner-friendly, with users able to compare the different models without needing expertise in deep learning or Python programming.
This would make it different from other similar packages, which require the user to set up their own experiments.

On the other hand, Fusilli should also be expert-friendly, with users who are more capable being able to change the training parameters, modify the models, and access the trained models for further experiments.\newline

\noindent\textbf{Wide applicability}:
Fusilli should include a wide variety of models, to ensure that the best model for a given task can be found.
Moreover, this would ensure that the package is useful for a wide range of users, as different users may have different requirements for model architectures based on their task and data.


\subsection{Fusion Methods}

Finding the models
Literature search - what words I used, not just healthcare but it came up a lot


Categorising the models - cui et al
\begin{itemize}
    \item Gathered models and then categorised them according to Cui et al. paper - a paper about diagnosis and prognosis deep learning multi modal fusion models.
    \item The paper included many models with different architectures and categorised based off underlying architecture.
    \item Usually categorisations are broad with early, late, and intermediate fusion but this paper had more categories which was useful for me.
    \item \textbf{Categories figure}
    \item Some models can fall into multiple categories, so chose the category that best described the model.
\end{itemize}

Which ones did I implement and why



Table of models, and benchmarks (uni-modal)

Link to documentation with diagrams of models


\section{Results}




\subsection{Diagram of workflow}

\subsection{Example usage and outputs}
Quick-start script with comments going through each line

Figures with output figures from the example notebooks

\subsection{Documentation}
Examples, templates for contributing, etc


\subsection{Reception}
\begin{itemize}
    \item JOSS paper - under review 
    \item GitHub stars and forks and articles
\end{itemize}

\section{Discussion}
\begin{itemize}
    \item Implemented a wide variety of models
    \item It will help people to know if data fusion is useful for their task and, if so, which model is best for their task
    \item Limitation and future work: Data inputs - images have to be .pt files and tabular data has to be .csv files. Would be nice to extend data inputs to be jpegs or niis for people less comfortable with Python.
    \item Limitation and future work: Only 2 modalities - could be extended to more
\end{itemize}

\section{Conclusion}
TBC...
% \begin{itemize}
%     \item Fusilli is a Python package for multimodal data fusion experimentation and analysis, specifically tackling the problem of lack of ways to compare models and lack of standardisation in the field.
%     \item I specifically made it for my PhD in fusing different data modalities in MND prognosis prediction
%     \item Link to next chapter on PPMI, ADNI, MIMIC: data fusion can be applied to any task where there are multiple data modalities describing one thing
%     \item Before going into MND, is there a clear benefit to different types of multimodal data fusion? Is there a consensus on the best approaches for different tasks?
%     \item MND sample size is small so we want to make sure we're using the best models by testing them on larger datasets with different applications
% \end{itemize}
